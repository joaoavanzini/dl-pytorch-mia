{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Introduction\n",
    "In this notebook we will preprocess the data for our classification task.<br />\n",
    "We will train a classifier to predict whether an X-Ray of a patient shows signs of pneumonia or not based on the RSNA Pneumonia Detection Challenge (https://www.kaggle.com/c/rsna-pneumonia-detection-challenge).\n",
    "\n",
    "At first we download the data from kaggle (https://www.kaggle.com/c/rsna-pneumonia-detection-challenge/data), by clicking on \"Download All\" and extract it afterwards.\n",
    "\n",
    "Acknowledgements:\n",
    "Wang X, Peng Y, Lu L, Lu Z, Bagheri M, Summers RM. ChestX-ray8: Hospital-scale Chest X-ray Database and Benchmarks on Weakly-Supervised Classification and Localization of Common Thorax Diseases. IEEE CVPR 2017, http://openaccess.thecvf.com/content_cvpr_2017/papers/Wang_ChestX-ray8_Hospital-Scale_Chest_CVPR_2017_paper.pdf\n",
    "\n",
    "Original Source: https://nihcc.app.box.com/v/ChestXray-NIHCC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Imports\n",
    "* pathlib for convenient path handling\n",
    "* pydicom for reading dicom files\n",
    "* numpy for storing the actual images\n",
    "* cv2 for directly resizing the images\n",
    "* pandas to read the provided labels\n",
    "* matplotlib for visualizing some images\n",
    "* tqdm for nice progress bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pydicom\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "At first, we read the csv file containing the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "labels = pd.read_csv(\"/path/to/rsna-pneumonia-detection-challenge/stage_2_train_labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "labels.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Note that subjects may occur multiple times in the dataset because different pneumonia spots are handled indivually. For our classification task, we can remove those duplicates as we are only interested in the binary label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Remove duplicate entries\n",
    "labels = labels.drop_duplicates(\"patientId\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's define the path to the dicom files and also the path were we want to store our processed npy files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ROOT_PATH = Path(\"/path/to/rsna-pneumonia-detection-challenge/stage_2_train_images/\")\n",
    "SAVE_PATH = Path(\"Processed/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's look at some example images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig, axis = plt.subplots(3, 3, figsize=(9, 9))\n",
    "c = 0\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        patient_id = labels.patientId.iloc[c]\n",
    "        dcm_path = ROOT_PATH/patient_id\n",
    "        dcm_path = dcm_path.with_suffix(\".dcm\")\n",
    "        dcm = pydicom.read_file(dcm_path).pixel_array\n",
    "        \n",
    "        label = labels[\"Target\"].iloc[c]\n",
    "        \n",
    "        axis[i][j].imshow(dcm, cmap=\"bone\")\n",
    "        axis[i][j].set_title(label)\n",
    "        c+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Dicom Reading & Effective storage\n",
    "\n",
    "In order to efficiently handle our data in the Dataloader, we convert the X-Ray images stored in the DICOM format to numpy arrays. Afterwards we compute the overall mean and standard deviation of the pixels of the whole dataset, for the purpose of normalization.\n",
    "Then the created numpy images are stored in two separate folders according to their binary label:\n",
    "* 0: All X-Rays which do not show signs of pneumonia\n",
    "* 1: All X-Rays which show signs of pneumonia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "To do so, we iterate over the patient ids and concat the patient ID with the ROOT_PATH.\n",
    "\n",
    "We then directly save the standardized and resized files into the corresponding directory (0 for healthy, 1 for pneumonia).\n",
    "This allows to take advantage of the ready-to-use torchvision **DatasetFolder** for simple file reading\n",
    "\n",
    "\n",
    "We standardize all images by the maximum pixel value in the provided dataset, 255.\n",
    "All images are resized to 224x224.\n",
    "\n",
    "To compute dataset mean and standard deviation, we compute the sum of the pixel values as well as the sum of the squared pixel values for each subject.\n",
    "This allows to compute the overall mean and standard deviation without keeping the whole dataset in memory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sums = 0\n",
    "sums_squared = 0\n",
    "\n",
    "for c, patient_id in enumerate(tqdm(labels.patientId)):\n",
    "    dcm_path = ROOT_PATH/patient_id  # Create the path to the dcm file\n",
    "    dcm_path = dcm_path.with_suffix(\".dcm\")  # And add the .dcm suffix\n",
    "    \n",
    "    # Read the dicom file with pydicom and standardize the array\n",
    "    dcm = pydicom.read_file(dcm_path).pixel_array / 255  \n",
    "        \n",
    "    # Resize the image as 1024x1024 is way to large to be handeled by Deep Learning models at the moment\n",
    "    # Let's use a shape of 224x224\n",
    "    # In order to use less space when storing the image we convert it to float16\n",
    "    dcm_array = cv2.resize(dcm, (224, 224)).astype(np.float16)\n",
    "    \n",
    "    # Retrieve the corresponding label\n",
    "    label = labels.Target.iloc[c]\n",
    "    \n",
    "    # 4/5 train split, 1/5 val split\n",
    "    train_or_val = \"train\" if c < 24000 else \"val\" \n",
    "        \n",
    "    current_save_path = SAVE_PATH/train_or_val/str(label) # Define save path and create if necessary\n",
    "    current_save_path.mkdir(parents=True, exist_ok=True)\n",
    "    np.save(current_save_path/patient_id, dcm_array)  # Save the array in the corresponding directory\n",
    "    \n",
    "    normalizer = dcm_array.shape[0] * dcm_array.shape[1]  # Normalize sum of image\n",
    "    if train_or_val == \"train\":  # Only use train data to compute dataset statistics\n",
    "        sums += np.sum(dcm_array) / normalizer\n",
    "        sums_squared += (np.power(dcm_array, 2).sum()) / normalizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mean = sums / 24000\n",
    "std = np.sqrt(sums_squared / 24000 - (mean**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We will use mean and std later in the dataloader to normalize our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Mean of Dataset: {mean}, STD: {std}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}