{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "strange-psychiatry",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Introduction\n",
    "In this notebook we will create and train the classifier on the chest x-ray dataset to classify whether an image shows signs of pneumonia or not"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sporting-timothy",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Imports:\n",
    "\n",
    "* torch and torchvision for model and dataloader creation\n",
    "* transforms from torchvision for Data Augmentation and Normalization\n",
    "* torchmetrics for easy metric computation\n",
    "* pytorch lightning for efficient and easy training implementation\n",
    "* ModelCheckpoint and TensorboardLogger for checkpoint saving and logging\n",
    "* tqdm for progress par when validating the model\n",
    "* numpy for all kinds of stuff :)\n",
    "* matplotlib for visualizing some images\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dressed-stereo",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torchmetrics\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "traditional-official",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "First we create our dataset.\n",
    "We can leverage the **DatasetFolder** from torchvision: It allows to simply pass a root directory and return return a dataset object with access to all files within the directory and the directory name as class label. <br />\n",
    "We only need to define a loader function, **load_file**, which defines how the files shall be loaded.\n",
    "This is very comfortable as we only have to load our previously stored numpy files.\n",
    "Additionally, we need to define a list of file extensions (just \"npy\" in our case).\n",
    "\n",
    "Finally we can pass a transformation sequence for Data Augmentation and Normalization.\n",
    "\n",
    "We use:\n",
    "* RandomResizedCrops which applies a random crop of the image and resizes it to the original image size (224x224)\n",
    "* Random Rotations between -5 and 5 degrees\n",
    "* Random Translation (max 5%)\n",
    "* Random Scaling (0.9-1.1 of original image size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "certified-canadian",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def load_file(path):\n",
    "    return np.load(path).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "explicit-plumbing",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "                                    transforms.ToTensor(),  # Convert numpy array to tensor\n",
    "                                    transforms.Normalize(0.49, 0.248),  # Use mean and std from preprocessing notebook\n",
    "                                    transforms.RandomAffine( # Data Augmentation\n",
    "                                        degrees=(-5, 5), translate=(0, 0.05), scale=(0.9, 1.1)),\n",
    "                                        transforms.RandomResizedCrop((224, 224), scale=(0.35, 1))\n",
    "\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "                                    transforms.ToTensor(),  # Convert numpy array to tensor\n",
    "                                    transforms.Normalize([0.49], [0.248]),  # Use mean and std from preprocessing notebook\n",
    "])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "varied-bread",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Finally, we create the train and val dataset and the corresponding data loaders.\n",
    "\n",
    "Please adapt batch size and num_workers according to your hardware ressources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "basic-scholarship",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.DatasetFolder(\n",
    "    \"Processed/train/\",\n",
    "    loader=load_file, extensions=\"npy\", transform=train_transforms)\n",
    "\n",
    "val_dataset = torchvision.datasets.DatasetFolder(\n",
    "    \"Processed/val/\",\n",
    "    loader=load_file, extensions=\"npy\", transform=val_transforms)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lyric-numbers",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's inspect some augmented train images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imported-september",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig, axis = plt.subplots(2, 2, figsize=(9, 9))\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        random_index = np.random.randint(0, 20000)\n",
    "        x_ray, label = train_dataset[random_index]\n",
    "        axis[i][j].imshow(x_ray[0], cmap=\"bone\")\n",
    "        axis[i][j].set_title(f\"Label:{label}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "static-boards",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 64#TODO\n",
    "num_workers = 4# TODO\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=False)\n",
    "\n",
    "print(f\"There are {len(train_dataset)} train images and {len(val_dataset)} val images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fixed-poetry",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The classes are imbalanced: There are more images without signs of pneumonia than with pneumonia.\n",
    "There are multiple ways to deal with imbalanced datasets:\n",
    "* Weighted Loss\n",
    "* Oversampling\n",
    "* Doing nothing :)\n",
    "\n",
    "In this example, we will simply do nothing as this often yields the best results.\n",
    "Buf feel free to play around with a weighted loss. A template to define a customized weighted loss function is provided below.\n",
    "\n",
    "Oversampling will be shown in a later lecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frequent-security",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "np.unique(train_dataset.targets, return_counts=True), np.unique(val_dataset.targets, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "educational-vinyl",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Model Creation in pytorch lightning\n",
    "\n",
    "Each pytorch lightning model is defined by at least an initialization method, a **forward** function which defines the forward pass/prediction, a **training_step** which yields the loss and **configure_optimizers** to specify the optimization algorithm.\n",
    "\n",
    "Additionally, we can use a **training_epoch_end** callback to compute overall dataset statistics and metrics such as accuracy.\n",
    "\n",
    "Subsequently, we define the **validation_step**. The validation step performs more or less the same steps as the training step, however, on the validation data. In this case, pytorch lightning doesn't update the weights.\n",
    "Again, we can use **validation_epoch_end** to compute overall dataset metrics.\n",
    "\n",
    "No loops or manual weight updates are needed!<br />\n",
    "Additionally, pl also handles device management.  Just pass the number of GPUS when creating the trainer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aquatic-demonstration",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Now it is time to create the model** - We will use the ResNet18 network architecture.\n",
    "\n",
    "As most of the torchvision models, the original ResNet expects a three channel input in **conv1**. <br />\n",
    "However, our X-Ray image data has only one channel.\n",
    "Thus we need to change the in_channel parameter from 3 to 1.\n",
    "\n",
    "Additionally, we will change the last fully connected layer to have only one output as we have a binary class label."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hundred-communication",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Optimizer and Loss\n",
    "We use the **Adam** Optimizer with a learning rate of 0.0001 and the **BinaryCrossEntropy** Loss function.<br />\n",
    "(In fact we use **BCEWithLogitsLoss** which directly accepts the raw unprocessed predicted values and computes the sigmoid activation function before applying Cross Entropy).\n",
    "Feel free to pass a weight different from 1 to the Pneumonia model in order to use the weighted loss function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opening-commissioner",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class PneumoniaModel(pl.LightningModule):\n",
    "    def __init__(self, weight=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.model = torchvision.models.resnet18()\n",
    "        # change conv1 from 3 to 1 input channels\n",
    "        self.model.conv1 = torch.nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "        # change out_feature of the last fully connected layer (called fc in resnet18) from 1000 to 1\n",
    "        self.model.fc = torch.nn.Linear(in_features=512, out_features=1)\n",
    "        \n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=1e-4)\n",
    "        self.loss_fn = torch.nn.BCEWithLogitsLoss(pos_weight=torch.tensor([weight]))\n",
    "        \n",
    "        # simple accuracy computation\n",
    "        self.train_acc = torchmetrics.Accuracy()\n",
    "        self.val_acc = torchmetrics.Accuracy()\n",
    "\n",
    "    def forward(self, data):\n",
    "        pred = self.model(data)\n",
    "        return pred\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x_ray, label = batch\n",
    "        label = label.float()  # Convert label to float (just needed for loss computation)\n",
    "        pred = self(x_ray)[:,0]  # Prediction: Make sure prediction and label have same shape\n",
    "        loss = self.loss_fn(pred, label)  # Compute the loss\n",
    "        \n",
    "        # Log loss and batch accuracy\n",
    "        self.log(\"Train Loss\", loss)\n",
    "        self.log(\"Step Train Acc\", self.train_acc(torch.sigmoid(pred), label.int()))\n",
    "        return loss\n",
    "    \n",
    "    \n",
    "    def training_epoch_end(self, outs):\n",
    "        # After one epoch compute the whole train_data accuracy\n",
    "        self.log(\"Train Acc\", self.train_acc.compute())\n",
    "        \n",
    "        \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # Same steps as in the training_step\n",
    "        x_ray, label = batch\n",
    "        label = label.float()\n",
    "        pred = self(x_ray)[:,0]  # make sure prediction and label have same shape\n",
    "\n",
    "        loss = self.loss_fn(pred, label)\n",
    "        \n",
    "        # Log validation metrics\n",
    "        self.log(\"Val Loss\", loss)\n",
    "        self.log(\"Step Val Acc\", self.val_acc(torch.sigmoid(pred), label.int()))\n",
    "        return loss\n",
    "    \n",
    "    def validation_epoch_end(self, outs):\n",
    "        self.log(\"Val Acc\", self.val_acc.compute())\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        #Caution! You always need to return a list here (just pack your optimizer into one :))\n",
    "        return [self.optimizer]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "armed-transparency",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = PneumoniaModel()  # Instanciate the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corresponding-death",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We create a checkpoint callback which only stores the 10 best models based on the validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "formal-cherry",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create the checkpoint callback\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='Val Acc',\n",
    "    save_top_k=10,\n",
    "    mode='max')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rotary-commodity",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Trainer documentation: https://pytorch-lightning.readthedocs.io/en/latest/common/trainer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cultural-lease",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create the trainer\n",
    "# Change the gpus parameter to the number of available gpus on your system. Use 0 for CPU training\n",
    "\n",
    "gpus = 1 #TODO\n",
    "trainer = pl.Trainer(gpus=gpus, logger=TensorBoardLogger(save_dir=\"./logs\"), log_every_n_steps=1,\n",
    "                     callbacks=checkpoint_callback,\n",
    "                     max_epochs=35)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "played-applicant",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "trainer.fit(model, train_loader, val_loader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indie-accreditation",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Evaluation\n",
    "\n",
    "Let's evaluate our model!\n",
    "At first, we load the latest checkpoint and send the model to the GPU, if possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "further-federation",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Use strict=False, otherwise we would want to match the pos_weight which is not necessary\n",
    "model = PneumoniaModel.load_from_checkpoint(\"weights/weights_1.ckpt\")\n",
    "model.eval()\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "certain-comparative",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Compute prediction on the complete validation set and store predictions and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polyphonic-church",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "preds = []\n",
    "labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, label in tqdm(val_dataset):\n",
    "        data = data.to(device).float().unsqueeze(0)\n",
    "        pred = torch.sigmoid(model(data)[0].cpu())\n",
    "        preds.append(pred)\n",
    "        labels.append(label)\n",
    "preds = torch.tensor(preds)\n",
    "labels = torch.tensor(labels).int()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prescribed-interstate",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Compute metrics:\n",
    "We can see that the overall result is already decent with our simple model.<br />\n",
    "However, we suffer from a large amount of False Negatives due to the data imbalance.<br />\n",
    "This is of particular importance in to avoid in medical imaging as missing findings might be fatal.<br />\n",
    "Feel free to try what happens if you increase or decrease the weight in the loss.\n",
    "\n",
    "An alternative to retraining with a weighted loss is to reduce the classification threshold from 0.5 to e.g 0.25. It produces way less false negatives but increases the number of False positives. <br />\n",
    "This is called the precision-recall tradeoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "twenty-korea",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "acc = torchmetrics.Accuracy()(preds, labels)\n",
    "precision = torchmetrics.Precision()(preds, labels)\n",
    "recall = torchmetrics.Recall()(preds, labels)\n",
    "cm = torchmetrics.ConfusionMatrix(num_classes=2)(preds, labels)\n",
    "cm_threshed = torchmetrics.ConfusionMatrix(num_classes=2, threshold=0.25)(preds, labels)\n",
    "\n",
    "print(f\"Val Accuracy: {acc}\")\n",
    "print(f\"Val Precision: {precision}\")\n",
    "print(f\"Val Recall: {recall}\")\n",
    "print(f\"Confusion Matrix:\\n {cm}\")\n",
    "print(f\"Confusion Matrix 2:\\n {cm_threshed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collectible-cotton",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig, axis = plt.subplots(3, 3, figsize=(9, 9))\n",
    "\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        rnd_idx = np.random.randint(0, len(preds))\n",
    "        axis[i][j].imshow(val_dataset[rnd_idx][0][0], cmap=\"bone\")\n",
    "        axis[i][j].set_title(f\"Pred:{int(preds[rnd_idx] > 0.5)}, Label:{labels[rnd_idx]}\")\n",
    "        axis[i][j].axis(\"off\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alternate-strength",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Congratulation! You made it to the end of the notebook and to the end of the classification lecture."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}